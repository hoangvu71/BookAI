# BookAI Architecture - Open WebUI with Vertex AI

## Overview

BookAI is a **production-ready** self-hosted AI chat interface that connects Open WebUI to Google Vertex AI through a custom OpenAI-compatible adapter. This architecture enables full access to Gemini 2.0 Flash capabilities while maintaining the familiar OpenAI API interface.

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ğŸŒ User Interface                 â”‚
â”‚         Open WebUI (Port 3000)             â”‚
â”‚   â€¢ Modern chat interface                  â”‚
â”‚   â€¢ Document RAG support                   â”‚
â”‚   â€¢ Multi-user management                  â”‚
â”‚   â€¢ PWA mobile support                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTP/WebSocket
                   â”‚ OpenAI API Format
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ğŸ”€ Translation Layer                 â”‚
â”‚      Vertex AI Adapter (Port 8000)         â”‚
â”‚   â€¢ OpenAI â†’ Vertex AI translation         â”‚
â”‚   â€¢ Streaming & non-streaming support      â”‚
â”‚   â€¢ Error handling & mapping               â”‚
â”‚   â€¢ Authentication bridge                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTPS
                   â”‚ Vertex AI REST API
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ğŸ§  AI Processing                    â”‚
â”‚      Google Vertex AI Platform             â”‚
â”‚   â€¢ Gemini 2.0 Flash Experimental          â”‚
â”‚   â€¢ Advanced reasoning capabilities        â”‚
â”‚   â€¢ Multimodal support                     â”‚
â”‚   â€¢ Production-grade scaling               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ… Current Implementation Status

### ğŸ¯ **PRODUCTION READY** - All Core Features Working

| Component | Status | Details |
|-----------|--------|---------|
| **Open WebUI** | âœ… **Production** | Official Docker image, fully configured |
| **Vertex AI Adapter** | âœ… **Production** | Custom Node.js service, tested & verified |
| **Authentication** | âœ… **Secure** | Service account key properly configured |
| **Streaming Chat** | âœ… **Working** | Real-time responses with proper SSE format |
| **Non-streaming** | âœ… **Working** | Standard request/response pattern |
| **Error Handling** | âœ… **Robust** | Proper error mapping and user feedback |

### ğŸ—ï¸ Implementation Details

#### **1. Open WebUI Frontend**
- **Image**: `ghcr.io/open-webui/open-webui:main`
- **Port**: 3000 (web interface)
- **Features**: All Open WebUI capabilities enabled
- **Configuration**: Points to our custom adapter endpoint

#### **2. Vertex AI Adapter Service**
- **Language**: Node.js with Express
- **Port**: 8000 (API endpoint)
- **Endpoints Implemented**:
  ```
  âœ… GET  /health              - Service health check
  âœ… GET  /v1/models           - Available models list
  âœ… POST /v1/chat/completions - Chat functionality (streaming + non-streaming)
  ```

#### **3. Google Cloud Integration**
- **Authentication**: Service account key (`config/service-account-key.json`)
- **Project**: `writing-book-457206`
- **Location**: `us-central1`
- **Model**: `gemini-2.0-flash-exp`

### ğŸ”§ Configuration Details

#### **Open WebUI Environment**
```bash
OPENAI_API_BASE_URL=http://vertex-adapter:8000/v1
OPENAI_API_KEY=vertex-ai-dummy-key
WEBUI_NAME=BookAI
ENABLE_RAG=true
ENABLE_SIGNUP=true
```

#### **Vertex Adapter Environment**
```bash
GOOGLE_CLOUD_PROJECT=writing-book-457206
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=/app/config/service-account-key.json
AI_MODEL=gemini-2.0-flash-exp
PORT=8000
LOG_LEVEL=info
```

## ğŸ¯ Architecture Benefits

### **1. Minimal Custom Development**
- Only the adapter layer is custom code (~200 lines)
- Open WebUI provides the entire frontend experience
- Reduces development time from months to days

### **2. Production-Grade Features** 
- **Complete UI**: Modern chat interface, dark mode, mobile support
- **User Management**: Multi-user support with authentication
- **RAG Support**: Document upload and chat functionality
- **Extensibility**: Plugin system and custom tools

### **3. Operational Excellence**
- **Container-Ready**: Full Docker Compose orchestration
- **Health Monitoring**: Built-in health checks and logging
- **Error Handling**: Proper error mapping and user feedback
- **Security**: Service account authentication with proper secret management

### **4. Future-Proof Design**
- **Model Flexibility**: Easy switching between Gemini models
- **Provider Agnostic**: Can adapt to other LLM providers
- **Open WebUI Updates**: Automatic access to new features
- **Scalable**: Ready for production deployment

## ğŸ“ Project Structure

```
BookAI/                           # ğŸ  Root directory
â”œâ”€â”€ vertex-adapter/               # ğŸ”€ Custom OpenAIâ†’Vertex AI adapter
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.js             # ğŸš€ Express server & middleware
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.js          # ğŸ’¬ Chat completions endpoint
â”‚   â”‚   â”‚   â””â”€â”€ models.js        # ğŸ“‹ Models listing endpoint
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ vertexai.js      # ğŸ§  Vertex AI integration service
â”‚   â”œâ”€â”€ Dockerfile               # ğŸ³ Adapter container definition
â”‚   â”œâ”€â”€ package.json             # ğŸ“¦ Node.js dependencies
â”‚   â””â”€â”€ package-lock.json        # ğŸ”’ Dependency lock file
â”œâ”€â”€ config/                      # âš™ï¸ Configuration files
â”‚   â””â”€â”€ service-account-key.json # ğŸ” Google Cloud credentials (gitignored)
â”œâ”€â”€ docker-compose.yml           # ğŸ³ Service orchestration
â”œâ”€â”€ .env                         # ğŸŒ Environment variables
â”œâ”€â”€ .gitignore                   # ğŸš« Version control exclusions
â”œâ”€â”€ README.md                    # ğŸ“– User documentation
â”œâ”€â”€ ARCHITECTURE.md              # ğŸ—ï¸ Technical architecture
â”œâ”€â”€ CLAUDE.md                    # ğŸ’» Development guidelines
â””â”€â”€ test-adapter.js              # ğŸ§ª Testing utilities
```

## ğŸ³ Docker Compose Architecture

```yaml
# Complete production setup
services:
  # Frontend: Open WebUI
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports: ["3000:8080"]
    environment:
      OPENAI_API_BASE_URL: http://vertex-adapter:8000/v1
      OPENAI_API_KEY: vertex-ai-dummy-key
      WEBUI_NAME: BookAI
    
  # Backend: Custom Vertex AI Adapter  
  vertex-adapter:
    build: ./vertex-adapter
    ports: ["8000:8000"]
    environment:
      GOOGLE_CLOUD_PROJECT: writing-book-457206
      AI_MODEL: gemini-2.0-flash-exp
    volumes:
      - "./config:/app/config:ro"
```

## ğŸ”„ Data Flow

### **Chat Request Flow**
1. **User** sends message via Open WebUI interface
2. **Open WebUI** makes HTTP POST to `/v1/chat/completions`
3. **Vertex Adapter** receives OpenAI-format request
4. **Adapter** translates to Vertex AI format and authenticates
5. **Vertex AI** processes request using Gemini 2.0 Flash
6. **Adapter** translates response back to OpenAI format
7. **Open WebUI** renders streaming response to user

### **Model Information Flow**
1. **Open WebUI** requests available models via `/v1/models`
2. **Vertex Adapter** returns configured Gemini model info
3. **Open WebUI** displays model in interface dropdown

## ğŸš€ Deployment Ready

This architecture is **production-ready** with:
- âœ… **Tested streaming & non-streaming chat**
- âœ… **Proper error handling & logging**
- âœ… **Secure credential management**
- âœ… **Health monitoring endpoints**
- âœ… **Container orchestration**
- âœ… **Documentation & troubleshooting guides**